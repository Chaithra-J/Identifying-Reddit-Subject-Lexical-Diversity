{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec50ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = \"jZPg1j9pWP-K0kY0TRg82w\" #your client id\n",
    "cs = \"RFDW7YgIq9YkSYomer46h5EUC8pMcQ\" #your client secret\n",
    "ua = \"hltassignment1\" #your user agent name\n",
    "sub = \"worldnews\" #the name of the subreddit (not including the 'r/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import requests\n",
    "import nltk\n",
    "import matplotlib\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=ci,\n",
    "    client_secret=cs,\n",
    "    user_agent=ua\n",
    ")\n",
    "\n",
    "\n",
    "with open(sub+\".txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "    \n",
    "    #on the following line you can change top to any of the previously mentioned ways of sorting \n",
    "    #and the limit to however many posts you would like to extract (here we extract just 10).\n",
    "    for post in reddit.subreddit(sub).top(limit=10): \n",
    "        \n",
    "        #this line collects the post titles\n",
    "        f.write(post.title+\"\\n\")\n",
    "        \n",
    "        #this line collects the post content\n",
    "        f.write(post.selftext+\"\\n\")\n",
    "        \n",
    "        #this section collects the comments\n",
    "        for comment in post.comments:\n",
    "            if isinstance(comment, MoreComments):\n",
    "                continue\n",
    "            f.write(comment.body+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37476d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(file):\n",
    "    with open(file, encoding='utf8') as f:\n",
    "        return ' '.join(line.strip() for line in f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = load_txt(sub+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3654a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(txt[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ee4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(txt)\n",
    "print(tokens[:30])\n",
    "\n",
    "tokens_processed = [t.lower() for t in tokens if t.isalnum()]\n",
    "print(tokens_processed[:30])\n",
    "\n",
    "fd = nltk.FreqDist(tokens_processed)\n",
    "print(fd.most_common(10))\n",
    "\n",
    "fd.plot(10)\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "tokens_filtered = [t for t in tokens_processed if t not in stopwords.words('english')]\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "tokens_stemmed = [porter.stem(w) for w in tokens_filtered]\n",
    "\n",
    "print(tokens_stemmed[:20]) #print the first 20 stemmed words\n",
    "\n",
    "fd = nltk.FreqDist(tokens_stemmed)\n",
    "print(fd.most_common(10))\n",
    "fd.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b15be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = lexical_diversity(tokens_processed)\n",
    "pre = lexical_diversity(tokens_filtered)\n",
    "\n",
    "print(\"Original:\", orig)\n",
    "print(\"Pre-Processed\", pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d670bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
